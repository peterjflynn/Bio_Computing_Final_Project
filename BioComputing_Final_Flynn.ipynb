{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peter Flynn\n",
    "# Winter, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal for this project is to create a script where the researcher will be able to blast any organism genome against all known viral genomes. The organism genome as well as the most up-to-date virus repository need to be downloaded from NCBI. I was trying to mimic the results of a paper where they blasted the pillbug *Armadillidium vulgare* genome against all complete viral genomes (Theze *et al.* 2014: doi:10.1093/gbe/evu163). \n",
    "\n",
    "This project presented some difficulties because I had to learn how to use the FTP server, work with large genome files, and how to use the blast software. \n",
    "\n",
    "Also, this script can only be performed using an os system since several of the commands seemed to be easier to complete in bash than to carry out exclusively in python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a directory where all your files will be stored and where you place the script and files. This directory can be made in your home directory for ease of use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Virus Genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the virus genomes need to be downloaded from NCBI, I first thought that I could use the ENTREZ module to download all (or any) of the virus genomes. It turns out (after days of trying) that even though ENTREZ is a great and easy way to download NCBI nucleotide and protein databases, it does not download complete genomes using the NCBI genome database. Therefore, I needed to figure out a different way to download all up-to-date complete virus genomes on NCBI. In order to do this I used the File Transfer Protocol (FTP) server. The python module\"ftplib\" is useful for connecting to an FTP server to retrieve files and process them locally. \n",
    "\n",
    "To get onto the FTP server for the NCBI database you have to connect to the host at \"ftp.ncbi.nlm.nih.gov\". From there you have to get to the virus genome directory within the genome database and find the file \"all.fna.tar.gz\". This file is refreshed whenever there is a new complete virus genome added to NCBI. The code below will download this file to the directory where this script is located.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded virus .fna file\n"
     ]
    }
   ],
   "source": [
    "#download your virus database\n",
    "import ftplib\n",
    "from ftplib import FTP\n",
    "host = \"ftp.ncbi.nlm.nih.gov\"\n",
    "ftp= FTP(host)\n",
    "ftp.login()\n",
    "ftp.cwd('genomes/Viruses') #find the genome virus directory within database\n",
    "#ftp.retrlines('LIST') #this lists the directory contents\n",
    "ftp.retrbinary('RETR all.fna.tar.gz', open('all.fna.tar.gz','wb').write) \n",
    "ftp.close() \n",
    "print(\"Downloaded virus .fna file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I created a subdirectory where the virus genomes can be stored once downloaded from the NCBI database. I titled this file \"all_virus_files\" for future reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create virus file in main directory\n",
    "import os\n",
    "import sys\n",
    "path = r'./all_virus_files' \n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to move the virus genome file into a subdirectory since there are more than 4500 seperate files in the all.fna.tar.gz once you untar it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./all_virus_files/all.fna.tar.gz'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move virus genome file to its own folder\n",
    "import shutil\n",
    "src = \"./all.fna.tar.gz\"\n",
    "dst = \"./all_virus_files/\"\n",
    "shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below will \"untar\" the all.fna.tar.gz file. Since the tar.gz file is compressed, one needs to decompress this file. I used the module tarfile, which makes it possible to read and extract the files from a tar.gz compressed file. I wrote a function that would allow me to extract the files or \"untar\" the files from all.fna.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted in Current Directory\n"
     ]
    }
   ],
   "source": [
    "#untar virus file \n",
    "import tarfile,sys \n",
    "def untar(file):\n",
    "    if (file.endswith(\"tar.gz\")):\n",
    "        tar = tarfile.open(file)\n",
    "        tar.extractall(path=\"./all_virus_files/\")\n",
    "        tar.close()\n",
    "        print(\"Extracted in Current Directory\")\n",
    "\n",
    "untar(\"./all_virus_files/all.fna.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the all.fna.tar.gz file decompressed for the complete virus genome database, every complete genome for every virus is inside its own subdirectory folder within all_virus_files. Therefore, we want to pull out the .fna file from each subdirectory.  I wrote a function that moves all the viruses from their own folder into the main all_virus_files folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull all virus fna files out of their seperate subfolders\n",
    "import shutil\n",
    "RootDir1 = r'./all_virus_files/'\n",
    "TargetFolder = r'./all_virus_files/'\n",
    "for root, dirs, files in os.walk((os.path.normpath(RootDir1)), topdown=False):\n",
    "        for name in files:\n",
    "            if name.endswith('fna'):\n",
    "                SourceFolder = os.path.join(root,name)\n",
    "                shutil.copy2(SourceFolder, TargetFolder) #copies fna to new folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the seperate virus .fna files are no longer in subfolders, you can easily concatenate all of the files into one .fna file to prepare for the BLAST. The easiest way I found to do this was to us the \"cat\" function in BASH. Once the virus genomes are all merged into one file it can be used as the query in the BLAST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate the virus files \n",
    "import os \n",
    "os.system(\"cd ./all_virus_files/ ;cat *.fna > merged_viruses.fna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step moves the merged virus file back into the home directory so it can be easily found when performing the BLAST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./merged_viruses.fna'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move merged_viruses.fna into the home directory\n",
    "import shutil \n",
    "src = \"./all_virus_files/merged_viruses.fna\"\n",
    "dst = \"./\"\n",
    "shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Organism Genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the project I chose to download the *Armadillidium vulgare* genome as my organism genome, however, any complete organism genome on the NCBI database could be input here. I first found where the genome was located on the FTP and then downloaded the specific file which contains the complete and most up-to-date genome. This script only works if you know where the organism's genome is located in the FTP. You can choose any organism genome you want, just replace the ftp.cwd with the path to that genome and wherever it states: GCA_001887335.1_A_vulgare_v1_genomic.fna.gz with the genome file you want to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-r--r--r--   1 ftp      anonymous   175168 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_assembly_report.txt\n",
      "-r--r--r--   1 ftp      anonymous     3405 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_assembly_stats.txt\n",
      "dr-xr-xr-x   3 ftp      anonymous     4096 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_assembly_structure\n",
      "-r--r--r--   1 ftp      anonymous   847387 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_cds_from_genomic.fna.gz\n",
      "-r--r--r--   1 ftp      anonymous   142192 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_feature_table.txt.gz\n",
      "-r--r--r--   1 ftp      anonymous  4671750 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_genomic.fna.gz\n",
      "-r--r--r--   1 ftp      anonymous  7016178 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_genomic.gbff.gz\n",
      "-r--r--r--   1 ftp      anonymous   311763 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_genomic.gff.gz\n",
      "-r--r--r--   1 ftp      anonymous   516390 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_protein.faa.gz\n",
      "-r--r--r--   1 ftp      anonymous   914598 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_protein.gpff.gz\n",
      "-r--r--r--   1 ftp      anonymous   207963 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_rm.out.gz\n",
      "-r--r--r--   1 ftp      anonymous      912 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_rm.run\n",
      "-r--r--r--   1 ftp      anonymous   852584 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_rna_from_genomic.fna.gz\n",
      "-r--r--r--   1 ftp      anonymous     1193 Nov 30 01:17 GCA_001887335.1_A_vulgare_v1_wgsmaster.gbff.gz\n",
      "lr--r--r--   1 ftp      anonymous       25 Nov 30 01:17 README.txt -> ../../../../../README.txt\n",
      "-r--r--r--   1 ftp      anonymous      410 Nov 30 01:17 annotation_hashes.txt\n",
      "-r--r--r--   1 ftp      anonymous       14 Mar 20 09:33 assembly_status.txt\n",
      "-r--r--r--   1 ftp      anonymous     1660 Nov 30 01:17 md5checksums.txt\n"
     ]
    }
   ],
   "source": [
    "#importing your organism genome \n",
    "import ftplib\n",
    "from ftplib import FTP\n",
    "host = \"ftp.ncbi.nlm.nih.gov\"\n",
    "ftp= FTP(host)\n",
    "ftp.login()\n",
    "ftp.cwd('genomes/genbank/invertebrate/Armadillidium_vulgare/latest_assembly_versions/GCA_001887335.1_A_vulgare_v1')\n",
    "ftp.retrlines('LIST')\n",
    "ftp.retrbinary('RETR GCA_001887335.1_A_vulgare_v1_genomic.fna.gz', open('GCA_001887335.1_A_vulgare_v1_genomic.fna.gz','wb').write)\n",
    "ftp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not part of the script, but if you hypothetically did not know where the organism genome was located, you could download the entire *Armadillidium vulgare* genome folder on the NCBI FTP server and then pick out the .fna files to see which might be the genome that you are looking for. To download the entire genome you could use the **wget** command in BASH and download all the files in the *Armadillidium vulgare* directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#potentially another way to download genomes from NCBI\n",
    "#import os \n",
    "#os.system(\"wget -r -nH -np -R index.html ftp://ftp.ncbi.nlm.nih.gov/genomes/genbank/invertebrate/Armadillidium_vulgare/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the organism genome is downloaded from the NCBI database you have to decompress the file. Since this is a .gz file not a .tar file you can import the gzip module and decompress the genome file by reading it into the gzip. I also renamed the file genome.fna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ungzip genome file this time use gzip because not a .tar.gz file but just a .gz file\n",
    "import gzip\n",
    "inF = gzip.open('GCA_001887335.1_A_vulgare_v1_genomic.fna.gz', 'rb')\n",
    "outF = open('genome.fna', 'wb')\n",
    "outF.write( inF.read() )\n",
    "inF.close()\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: BLAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can perform a BLAST search online through a module in Biopython called Blast, however, since the viral genomes file is so large, we cannot use BLAST for this script. Therefore, it is easier to run BLAST locally on your computer. This piece of the script only works for an OS system, however on the FTP server there are files for linux and windows systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-r--r--r--   1 ftp      anonymous       85 Dec  7 23:19 ChangeLog\n",
      "-r--r--r--   1 ftp      anonymous 16006645 Dec  7 23:15 ncbi-blast-2.6.0+-1.src.rpm\n",
      "-r--r--r--   1 ftp      anonymous       62 Dec  7 23:20 ncbi-blast-2.6.0+-1.src.rpm.md5\n",
      "-r--r--r--   1 ftp      anonymous 179851100 Dec  7 23:15 ncbi-blast-2.6.0+-1.x86_64.rpm\n",
      "-r--r--r--   1 ftp      anonymous       65 Dec  7 23:20 ncbi-blast-2.6.0+-1.x86_64.rpm.md5\n",
      "-r--r--r--   1 ftp      anonymous 20025526 Dec  7 23:20 ncbi-blast-2.6.0+-src.tar.gz\n",
      "-r--r--r--   1 ftp      anonymous       63 Dec  7 23:20 ncbi-blast-2.6.0+-src.tar.gz.md5\n",
      "-r--r--r--   1 ftp      anonymous 23400924 Dec  7 23:20 ncbi-blast-2.6.0+-src.zip\n",
      "-r--r--r--   1 ftp      anonymous       60 Dec  7 23:20 ncbi-blast-2.6.0+-src.zip.md5\n",
      "-r--r--r--   1 ftp      anonymous 83610445 Jan  3 17:21 ncbi-blast-2.6.0+-win64.exe\n",
      "-r--r--r--   1 ftp      anonymous       62 Dec  7 23:20 ncbi-blast-2.6.0+-win64.exe.md5\n",
      "-r--r--r--   1 ftp      anonymous 222504398 Dec  7 23:17 ncbi-blast-2.6.0+-x64-linux.tar.gz\n",
      "-r--r--r--   1 ftp      anonymous       69 Dec  7 23:20 ncbi-blast-2.6.0+-x64-linux.tar.gz.md5\n",
      "-r--r--r--   1 ftp      anonymous 128253020 Dec  7 23:19 ncbi-blast-2.6.0+-x64-macosx.tar.gz\n",
      "-r--r--r--   1 ftp      anonymous       70 Dec  7 23:20 ncbi-blast-2.6.0+-x64-macosx.tar.gz.md5\n",
      "-r--r--r--   1 ftp      anonymous 83358626 Jan  3 17:21 ncbi-blast-2.6.0+-x64-win64.tar.gz\n",
      "-r--r--r--   1 ftp      anonymous       69 Jan  6 21:14 ncbi-blast-2.6.0+-x64-win64.tar.gz.md5\n",
      "-r--r--r--   1 ftp      anonymous 129269595 Dec  7 23:18 ncbi-blast-2.6.0+.dmg\n",
      "-r--r--r--   1 ftp      anonymous       56 Dec  7 23:20 ncbi-blast-2.6.0+.dmg.md5\n",
      "downloaded blast\n"
     ]
    }
   ],
   "source": [
    "#download blast\n",
    "import ftplib\n",
    "from ftplib import FTP\n",
    "host = \"ftp.ncbi.nlm.nih.gov\"\n",
    "ftp= FTP(host)\n",
    "ftp.login()\n",
    "ftp.cwd('/blast/executables/blast+/LATEST/')\n",
    "ftp.retrlines('LIST')\n",
    "ftp.retrbinary('RETR ncbi-blast-2.6.0+-x64-macosx.tar.gz', open('ncbi-blast-2.6.0+-x64-macosx.tar.gz','wb').write) \n",
    "ftp.close()\n",
    "print('downloaded blast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the BLAST install file is a tar.gz file, it needs to be decompressed, which is again done through the tarfile module, in the same function we used for decompressing the viral genomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted in Current Directory\n"
     ]
    }
   ],
   "source": [
    "#untar blast install file \n",
    "import tarfile,sys \n",
    "def untar(file):\n",
    "    if (file.endswith(\"tar.gz\")):\n",
    "        tar = tarfile.open(file)\n",
    "        tar.extractall(path=\"./\")\n",
    "        tar.close()\n",
    "        print(\"Extracted in Current Directory\")\n",
    "\n",
    "untar(\"./ncbi-blast-2.6.0+-x64-macosx.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the BLAST files are decompressed I put these files into the home directory so there is an easy place to find the BLAST application for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../ncbi-blast-2.6.0+'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copy program files into home directory\n",
    "import shutil \n",
    "src = \"./ncbi-blast-2.6.0+\"\n",
    "dst = \"../\"\n",
    "shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the BLAST file is installed, it is time to prepare your files for the BLAST.\n",
    "\n",
    "Either the organism genome file or the virus genome file needs to be made into the database. According to the Theze et al. 2014, they used the pillbug genome as their database and the virus genomes file as their query. Therefore, I am making the organism genome the database for this blast. The database is created and called: \"genome_db\" which consists of three different files in your directory. \n",
    "makeblastdb is the command in BLAST that creates a database\n",
    "-in is the input file\n",
    "-dbtype specifies what kind of data the input file (nucleotide, protein, etc.)\n",
    "-out specifies what you want the output to be called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make organism genome the database\n",
    "import os \n",
    "os.system(\"makeblastdb -in genome.fna -dbtype nucl -out genome_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since tblastx takes a long time to run, I have shortened the merged viruses file to only 4000 lines (merged_viruses_short.fna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cut file to be small for tblastx\n",
    "import os \n",
    "os.system('head -4000 merged_viruses.fna > merged_viruses_short.fna')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to run your BLAST. We will be performing a tblastx, which compares the six-frame translations of a nucleotide query sequence against the six-frame translations of a nucleotide sequence database. This is the most computationally expensive BLAST technique. It is a powerful gene-predicition tool.\n",
    "\n",
    "\n",
    "-db is designating which file is the database\n",
    "\n",
    "-query is designating which files is the query \n",
    "\n",
    "-evalue describes the number of hits one can \"expect\" to see by chance when searching a database of a particular size. An evalue of 1 was set by Theze et al 2014.\n",
    "\n",
    "-culling_limit discards hits that have a certain number of reads that are better than it (in this script it only saves the best hit)\n",
    "\n",
    "-outfmt is the format you want the output, 5 = xml file\n",
    "\n",
    "-out specifies what you want the output to be called\n",
    "\n",
    "Since tBlastx takes several hours to run for this job, I provided the end result of the tblastx (tblastx.xml) as well as the version with only 4000 lines from the shortened merged viruses file (tblastx_hits_short.xml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run tBlastx\n",
    "import os \n",
    "cmd = \"tblastx -query merged_viruses_short.fna -db genome_db -evalue 1 -culling_limit 1 -outfmt 5 -out tblastx_hits_short.xml\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have provided the tblastx.xml hits file that would have been produced from the full tblastx.\n",
    "\n",
    "This xml file gives us the best protein hit for each virus. If you put the .xml file into Geneious or another software that can read .xml files, it gives you the viral protein fragment hit (hsp_hseq). To perform a subsequent blastp analysis on this file you need to select the genome protein fragment hits instead (hsp_qseq). Cutting out the pillbug genome protein fragment hits can be performed using a regular expression since before every genome protein fragment has a distinctive Hsp_qseq before and after it. I then can join all of these genome protein sequences onto their own line in a new textfile \"tblastx.txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take out the Hsp_qseq with regex\n",
    "import Bio\n",
    "import re\n",
    "with open(\"tblastx_hits.xml\", \"r\") as f:  \n",
    "        strings = (re.findall(r'(?<=<Hsp_qseq>).*(?=\\<)', f.read()))\n",
    "        g = (\"\\n\".join(strings)) #can join each fragment into a newline\n",
    "        with open(\"tblastx_hits.txt\", \"w\") as outp:\n",
    "            outp.write(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a text file with every pillbug genome fragment that was a hit on the tblastx, we can add a symbol (>) and unique number identifier for each protein sequence and convert this textfile to a fasta file in order to be able to continue working with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add >number and create FASTA file\n",
    "openFile= open('./tblastx_hits.txt', \"r\")\n",
    "newFile = open('tblastx_hits.fasta', 'w')\n",
    "count = 0\n",
    "for lines in openFile:\n",
    "    newFile.write(('>'+str(count)+'\\n'+ lines))\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to blastp the tblastx_hits.fasta file against the non-redundant protein database. The goal now is to screen the selected subset of *A. vulgare* genome sequences as queries to screen for homologous coding sequences in the whole set of nonredundant protein sequences of the National Center for Biotechnology Information (NCBI) database. The non-redundant database is over 100GB of storage, so I do not have that downloaded on my computer. It is best to use a server that has this database already downloaded to run a blastp.\n",
    "\n",
    "Since our file is still too large to use online, we will cut a small portion to use run a blastp on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run Blastp\n",
    "#import os \n",
    "#cmd = \"blastp -query tblastx_hits.fasta -db nr -evalue 0.01 -outfmt 5 -out tblastx_hits.xml\"\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as far as I have gotten since I have not had a chance to use the Field Museum server to perform a blastp (which has the non-redundant protein database downloaded). "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
